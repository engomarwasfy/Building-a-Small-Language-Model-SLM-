{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc82b3ed-1c3d-4ba5-a846-304ffd977fee",
   "metadata": {
    "id": "cc82b3ed-1c3d-4ba5-a846-304ffd977fee"
   },
   "source": [
    "# The following Notebook is my attempt to build a Small Language Model, I have referred a few resources which i have attached in my Readme file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38cc2cc6-3f52-4d44-a2e5-04630c265081",
   "metadata": {
    "id": "38cc2cc6-3f52-4d44-a2e5-04630c265081"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (2024.9.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (3.10.11)\n",
      "Requirement already satisfied: packaging in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: xxhash in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: filelock in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: pandas in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from aiohttp->datasets) (1.15.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from huggingface-hub>=0.23.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from huggingface-hub>=0.23.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
     ]
    }
   ],
   "source": "!pip install -U datasets"
  },
  {
   "cell_type": "markdown",
   "id": "6f75ccdf-c302-41ed-96c6-181c37d4a529",
   "metadata": {
    "id": "6f75ccdf-c302-41ed-96c6-181c37d4a529"
   },
   "source": [
    "# I will use the TinyStories dataset to develop the small language model,\n",
    "# There ~2 Million stories (rows) and ~ 20,000 stories for validation, so the loading\n",
    "# might take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c896954-83ae-488b-9c6c-26d13505639d",
   "metadata": {
    "id": "7c896954-83ae-488b-9c6c-26d13505639d"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "df = load_dataset(\"roneneldan/TinyStories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c337437d-94f7-4c3b-be03-6dd006fd68b0",
   "metadata": {
    "id": "c337437d-94f7-4c3b-be03-6dd006fd68b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 2119719\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 21990\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f9148fd-bf6a-45fd-ae38-d3dc7031c0e3",
   "metadata": {
    "id": "3f9148fd-bf6a-45fd-ae38-d3dc7031c0e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (2119719, 1), 'validation': (21990, 1)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3133a974-d11c-4608-8c77-e1ce8801ed38",
   "metadata": {
    "id": "3133a974-d11c-4608-8c77-e1ce8801ed38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5e522b-6a77-48e0-a38d-25e87813f44b",
   "metadata": {
    "id": "4c5e522b-6a77-48e0-a38d-25e87813f44b"
   },
   "source": [
    "Step 1: We will use a tokenization scheme that is necessary before converting the data into a numeric form and then passing it to the SLM.\n",
    "We will use BPE (Byte Pair Encoding algorithm, a sub word tokenizer.....has many advantages over word or just character based tokenization approaches)...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0833d980-415b-4b24-bcdb-7046c5cd35d2",
   "metadata": {
    "id": "0833d980-415b-4b24-bcdb-7046c5cd35d2"
   },
   "source": [
    "so every row corresponds to a story...and for every token in that row we will have a token id and it will be merged...\n",
    "We will store every token id in a .bin file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa8e876-61f9-410b-a1e7-5b1d5f92b610",
   "metadata": {
    "id": "1aa8e876-61f9-410b-a1e7-5b1d5f92b610"
   },
   "source": [
    ".bin file bcoz, it will get stored on the disk and the processing will be faster, since our data is too big (production level), it will avoid any sort of RAM overload and we can reuse the .bin file for training...also no need to retokenize again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ed73f-5736-4849-80c2-ddc0bc8fe5ec",
   "metadata": {
    "id": "b97ed73f-5736-4849-80c2-ddc0bc8fe5ec"
   },
   "source": [
    "We will also need to make sure that it is memory mapped using np.memmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d1f6cb-785c-42ab-aba9-fb6c24f3e59f",
   "metadata": {
    "id": "e8d1f6cb-785c-42ab-aba9-fb6c24f3e59f"
   },
   "source": [
    "We will also do chunking, that is divide the data into batches and then store these batches in a train.bin file that will be present on the disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed389d-2870-41eb-b985-efd6a79ab6bd",
   "metadata": {
    "id": "06ed389d-2870-41eb-b985-efd6a79ab6bd"
   },
   "source": [
    "Batches makes the processing faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5a3b586-2c2c-4a47-9893-8269ccd211c5",
   "metadata": {
    "id": "d5a3b586-2c2c-4a47-9893-8269ccd211c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from tiktoken) (2.32.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68244ab7-0838-48f7-92fd-239ac8d79db0",
   "metadata": {
    "id": "68244ab7-0838-48f7-92fd-239ac8d79db0"
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import tiktoken\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27ad0a97-94b3-4b2f-875f-50809368da47",
   "metadata": {
    "id": "27ad0a97-94b3-4b2f-875f-50809368da47"
   },
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deef1c94-c812-470c-9ea2-429a79b55817",
   "metadata": {
    "id": "deef1c94-c812-470c-9ea2-429a79b55817"
   },
   "outputs": [],
   "source": [
    "def processing(sample_text):\n",
    "    ids = encoding.encode_ordinary(sample_text['text'])\n",
    "    out = {'ids':ids,'len':len(ids)}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e6a8e1b-5bca-4c47-9929-020c7b533c5a",
   "metadata": {
    "id": "0e6a8e1b-5bca-4c47-9929-020c7b533c5a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ffa49d1b584efaba6d98adea879e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing the splits (num_proc=8):   0%|          | 0/2119719 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f19322460c4dd7957e984f3a433615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing the splits (num_proc=8):   0%|          | 0/21990 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a118074672b4a9fa0bd5ef844268312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "writing train.bin:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa9b717d2e549f8999a9cc34c4ce6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "writing validation.bin:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists(\"train.bin\"):\n",
    "    tokenized = df.map(\n",
    "        processing, # our token processing function defined above....basically we are mapping teh data here...:)\n",
    "        remove_columns=['text'],\n",
    "        desc=\"tokenizing the splits\",\n",
    "        num_proc=8,\n",
    "        )\n",
    "    for split, dset in tokenized.items():\n",
    "        arr_len = np.sum(dset['len'], dtype=np.uint64)\n",
    "        filename = f'{split}.bin'\n",
    "        dtype = np.uint16 # this tells you the total bits, so 16 here so 2^16 possible tokens which very well fits our training data\n",
    "        arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))\n",
    "        total_batches = 1024\n",
    "        idx = 0\n",
    "        for batch_idx in tqdm(range(total_batches), desc=f'writing {filename}'):\n",
    "            # We will Batch together samples for faster write\n",
    "            batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy')\n",
    "            arr_batch = np.concatenate(batch['ids'])\n",
    "            # Here we write into mmap\n",
    "            arr[idx : idx + len(arr_batch)] = arr_batch\n",
    "            idx += len(arr_batch)\n",
    "        arr.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1a3f48-5502-443e-a0c2-bfd968a6e3d5",
   "metadata": {
    "id": "7c1a3f48-5502-443e-a0c2-bfd968a6e3d5"
   },
   "source": [
    "Now we will have to creat input output pairs..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45817278-082b-4c9f-8e04-2f5cd4d4364a",
   "metadata": {
    "id": "45817278-082b-4c9f-8e04-2f5cd4d4364a"
   },
   "source": [
    "We will now have to define following things first..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b759fd7-238e-4245-9bd7-f5476a024c3a",
   "metadata": {
    "id": "5b759fd7-238e-4245-9bd7-f5476a024c3a"
   },
   "source": [
    "Context size (what the slm sees before predicting the next token)\n",
    "we will use the context_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc272d8d-9806-43af-965f-999e929c3d8d",
   "metadata": {
    "id": "bc272d8d-9806-43af-965f-999e929c3d8d"
   },
   "source": [
    "After this stage the model has no idea about the raws words it will just see the token IDs, so if they are like [23,43,56,34,7,3,....], the ontext size of 4 means that the model will see [23,43,56,34] and predict the next token as [7], this will be done across all the tokens of train.bin file, which i think will probably have more than 100 million training ids on record!!!, we will not play around with strides, each step will the output as one placed of the input token shifted by 1 in the actual train.bin file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e037d6-aa4d-46a9-8ff6-cb292a4d8203",
   "metadata": {
    "id": "b2e037d6-aa4d-46a9-8ff6-cb292a4d8203"
   },
   "source": [
    "Now wee need batches, batch size = 6 here, to reduce the time to update the entire params while backpropagating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a33a1a5-11b5-4b83-9052-0bdd9d20bcba",
   "metadata": {
    "id": "7a33a1a5-11b5-4b83-9052-0bdd9d20bcba"
   },
   "source": [
    "Now we have an input tensor and an output tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152ec24e-0011-4598-a1c2-71ad283d8246",
   "metadata": {
    "id": "152ec24e-0011-4598-a1c2-71ad283d8246"
   },
   "source": [
    "Since context size is 4, for each row in the input and output tensor, we have four prediction tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ac7ae3-bd56-4787-bcab-d88d96d1a04a",
   "metadata": {
    "id": "98ac7ae3-bd56-4787-bcab-d88d96d1a04a"
   },
   "source": [
    "For example: X1 = [23,4,2,66] and y1 = [4,2,66,8], for this i/p o/p pair, we are esentially predicting 4 sentences,i.e, if 23 is input, 4 is the output, if 23,4 is input then 2 is output, if 23,4,2 is input then 66 is output and if 23,4,2,66 i input then 8 is the output..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2793f0ff-b431-4526-bb9d-c55c4d547f37",
   "metadata": {
    "id": "2793f0ff-b431-4526-bb9d-c55c4d547f37"
   },
   "source": [
    "What i am essentially going to do here is create random batches, meaning X1,X2....etc can be from anywhere in the originial data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cb7d4d-6a66-47db-8b1e-2a19efd5c6f4",
   "metadata": {
    "id": "60cb7d4d-6a66-47db-8b1e-2a19efd5c6f4"
   },
   "source": [
    "## I will also implement Memory Locking so that we have reserved memory in the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c152fae0-78f5-4e0d-bd93-6224e42eef62",
   "metadata": {
    "id": "c152fae0-78f5-4e0d-bd93-6224e42eef62"
   },
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    if split == 'train':\n",
    "        data = np.memmap('train.bin', dtype=np.uint16, mode='r')\n",
    "    else:\n",
    "        data = np.memmap('validation.bin', dtype=np.uint16, mode='r')\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.from_numpy((data[i:i+block_size]).astype(np.int64)) for i in ix])\n",
    "    y = torch.stack([torch.from_numpy((data[i+1:i+1+block_size]).astype(np.int64)) for i in ix])\n",
    "    if device_type == 'cuda':\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ae8477-36cd-44ef-b23c-94c45a24a128",
   "metadata": {
    "id": "d8ae8477-36cd-44ef-b23c-94c45a24a128"
   },
   "source": [
    "in the above cell, we are stacking x1,x2....etc into x, ix is the random id of the batches which i have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e119fe00-51e4-4266-825a-bd09f76b729c",
   "metadata": {
    "id": "e119fe00-51e4-4266-825a-bd09f76b729c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from contextlib import nullcontext\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5899c734-d51b-4ba1-b805-b6c4615e961a",
   "metadata": {
    "id": "5899c734-d51b-4ba1-b805-b6c4615e961a"
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, ndim, bias):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(ndim))\n",
    "        self.bias = nn.Parameter(torch.zeros(ndim)) if bias else None\n",
    "    def forward(self, x):\n",
    "        return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb8428a-db1b-4440-b8e3-d211d751d9e1",
   "metadata": {
    "id": "1fb8428a-db1b-4440-b8e3-d211d751d9e1"
   },
   "source": [
    "NOTE: It is important to have Layer Normalization, bcoz of several reasons, some of them i have mentioned in my blog here while trying to explain the DyTs (Transformers without Normalization) check out here :https://medium.com/@kakadechaitanya77/what-exactly-is-transformers-without-normalization-dyt-part-1-3cdeae976c00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25074706-89c0-48f0-a263-cfad629bbc92",
   "metadata": {
    "id": "25074706-89c0-48f0-a263-cfad629bbc92"
   },
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.flash = hasattr(F, 'scaled_dot_product_attention')\n",
    "        if not self.flash:\n",
    "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "                                       .view(1, 1, config.block_size, config.block_size))\n",
    "#This part of the code, i have introduced\n",
    "#the attention mechanism of the transformer architecture...\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)\n",
    "\n",
    "\n",
    "        if self.flash:\n",
    "            y = F.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.attn_dropout.p if self.training else 0.0, is_causal=True)\n",
    "        else:\n",
    "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "            att = att.masked_fill(self.bias[:, :, :T, :T] == 0, float('-inf'))\n",
    "            att = F.softmax(att, dim=-1)\n",
    "            att = self.attn_dropout(att)\n",
    "            y = att @ v\n",
    "\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69547e71-58ef-427e-986a-b811d0b3e8a8",
   "metadata": {
    "id": "69547e71-58ef-427e-986a-b811d0b3e8a8"
   },
   "source": [
    "Following is the MLP architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ff8bce9-2097-4962-8c69-e8af83a788c9",
   "metadata": {
    "id": "0ff8bce9-2097-4962-8c69-e8af83a788c9"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.c_proj = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.c_proj(self.gelu(self.c_fc(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa2d605-9883-46b1-a285-5d6e1de490d7",
   "metadata": {
    "id": "6fa2d605-9883-46b1-a285-5d6e1de490d7"
   },
   "source": [
    "Now ,  I will create the Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90e75443-7d68-43b5-a772-e6b63e5c00f9",
   "metadata": {
    "id": "90e75443-7d68-43b5-a772-e6b63e5c00f9"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln2 = LayerNorm(config.n_embd, config.bias)\n",
    "        self.mlp = MLP(config)\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.mlp(self.ln2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c75f4-9070-4177-ad10-e6b725a5d305",
   "metadata": {
    "id": "cb3c75f4-9070-4177-ad10-e6b725a5d305"
   },
   "source": [
    "x = x + self.attn(self.ln1(x))\n",
    "x = x + self.mlp(self.ln2(x))\n",
    "If you analyse this two lines deeply, these are basically the residual connections or skip connections (as in the ResNet architecture), They will help the past gradients flow into the future, so that meaning or importance (long term dependency is not lost) Think of the vanishing gradient issues that can prevent the NN to larn from the previous deep inputs and weight updation slows...thereby increasing the training time...!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d95f97d4-8339-4d8d-96cd-1276a29de712",
   "metadata": {
    "id": "d95f97d4-8339-4d8d-96cd-1276a29de712"
   },
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int\n",
    "    vocab_size: int\n",
    "    n_layer: int\n",
    "    n_head: int\n",
    "    n_embd: int\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.transformer = nn.ModuleDict(dict(\n",
    "            wte=nn.Embedding(config.vocab_size, config.n_embd),\n",
    "            wpe=nn.Embedding(config.block_size, config.n_embd),\n",
    "            drop=nn.Dropout(config.dropout),\n",
    "            h=nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
    "            ln_f=LayerNorm(config.n_embd, config.bias),\n",
    "        ))\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
    "        self.transformer.wte.weight = self.lm_head.weight  # weight tying\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        for pn, p in self.named_parameters():\n",
    "            if pn.endswith('c_proj.weight'):\n",
    "                nn.init.normal_(p, mean=0.0, std=0.02 / math.sqrt(2 * config.n_layer))\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        device = idx.device\n",
    "        b, t = idx.size()\n",
    "        assert t <= self.config.block_size\n",
    "        pos = torch.arange(0, t, dtype=torch.long, device=device)\n",
    "\n",
    "        tok_emb = self.transformer.wte(idx)\n",
    "        pos_emb = self.transformer.wpe(pos)\n",
    "        x = self.transformer.drop(tok_emb + pos_emb)\n",
    "        for block in self.transformer.h:\n",
    "            x = block(x)\n",
    "        x = self.transformer.ln_f(x)\n",
    "\n",
    "        if targets is not None:\n",
    "            logits = self.lm_head(x)   #this is out logits matrix which i have explaine below...\n",
    "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1) # the loss is cross entropy\n",
    "            return logits, loss\n",
    "        else:\n",
    "            logits = self.lm_head(x[:, [-1], :])\n",
    "            return logits, None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Generate tokens given a conditioning sequence.\n",
    "        idx: Tensor of shape (B, T)\n",
    "        \"\"\"\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature\n",
    "            if top_k is not None:\n",
    "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4af0bc-5234-49c1-b558-140670cdb1dd",
   "metadata": {
    "id": "dd4af0bc-5234-49c1-b558-140670cdb1dd"
   },
   "source": [
    "# Now we will lool at how the output is actually computed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0608e74-abde-4360-aacf-5ae9012c9420",
   "metadata": {
    "id": "e0608e74-abde-4360-aacf-5ae9012c9420"
   },
   "source": [
    "So the output of our transformer block is 4*768, where 4 is the context size and 768 is the vector dimension of the embeddings given as the lm_head in the code above...(which is also caled as the logits matrix)....\n",
    "\n",
    "Note: This logits matrix gets used for the next token/word prediction task....\n",
    "\n",
    "Now what we want is to predict the next token! How do we do that from the logits matrix??\n",
    "so, i know that eaxh of the batch itself has 4 prediction tasks as explained in some cell above... every token in the batch has now an output dimension equal to the vocab size (Think of the logits matrix and rows and columns, where rows size is 4 as that was our context size and the columns lenght is vacab size, eaxh row is the token)so if we look at the first token, we will see VOCABSIZE number of probability values and the one with highes prob is the corresponding next token in as indexes by the vocabulary..... WOW!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f33dc7-d64a-45c0-982c-9ccf204597e9",
   "metadata": {
    "id": "c5f33dc7-d64a-45c0-982c-9ccf204597e9"
   },
   "source": [
    "We then compare the output values with original batch and then compute loss and we want to minimize this loss then....We use BackPropagation mechanism!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22273c3b-096b-4be3-8e79-a0530ed74ae9",
   "metadata": {
    "id": "22273c3b-096b-4be3-8e79-a0530ed74ae9"
   },
   "source": [
    "\n",
    "\n",
    "There will be 4 losses as the batch size we have taken is 4, so let these individual losses be L1,L2,L3 and L4, so the net Loss is L1+L2+L3+L4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf854d6-ed25-47ad-8c96-00dd773b89f6",
   "metadata": {
    "id": "6bf854d6-ed25-47ad-8c96-00dd773b89f6"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " I have also done some Initializations which are mentioned as below:\n",
    "These are basically the trainable params:\n",
    "Token embedding layer (wte)\n",
    "pos embedding layer (wpe)\n",
    "1st attention block (layerNorm before)\n",
    "QKV linear (c_attn)\n",
    "output c_proj\n",
    "2nd attention block (Layer norm before MLP)\n",
    "MLP block (c_fc)\n",
    "output c_proj\n",
    "final layer norm\n",
    "output head lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fdae0bb-3569-4d24-be5a-05dca1333743",
   "metadata": {
    "id": "9fdae0bb-3569-4d24-be5a-05dca1333743"
   },
   "outputs": [],
   "source": [
    "config = GPTConfig(\n",
    "    vocab_size=50257,\n",
    "    block_size=128,       # here i have taken the context size of 128, i used 4 only for explanation\n",
    "    n_layer=6, # no of layer is the transformer blocks' number that u use...\n",
    "    n_head=6, #no of attention heads as in Multi Head Attention\n",
    "    n_embd=384, # The embedding dimension .... try chnaging thinhs in this code here and there\n",
    "    dropout=0.1,\n",
    "    bias=True\n",
    ")\n",
    "\n",
    "model = GPT(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be174888-b920-42bb-94eb-64976bd2b9a7",
   "metadata": {
    "id": "be174888-b920-42bb-94eb-64976bd2b9a7"
   },
   "source": [
    "The loss function is essentially cross entropy (i.e negative log likelihood), we see the probability values of the correct output token in the logits matrix\n",
    "and we want that value to be as close to 1 as possible\n",
    "so for a batch of size four, we will have original output p1,p2,p3 and p4 whose values must be 1 iteratively and the predicted probabilities this will be for each item in batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53efca0b-52fb-4f3e-a2f1-22cd21e7379b",
   "metadata": {
    "id": "53efca0b-52fb-4f3e-a2f1-22cd21e7379b"
   },
   "outputs": [],
   "source": [
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for split in ['train', 'val']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "                X, Y = get_batch(split)\n",
    "                with ctx:\n",
    "                    logits, loss = model(X, Y)\n",
    "                losses[k] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8965dbb2-b031-47d4-9636-a2d1a7b78d4a",
   "metadata": {
    "id": "8965dbb2-b031-47d4-9636-a2d1a7b78d4a"
   },
   "source": [
    "Note : I will be using the AMP ( Automatic Mixed Precision Method) That will automatically decide which Floating Point Precision to be used\n",
    "This will dynamically make the processing faster and overall improved efficiency!\n",
    "For example: when any matrix calculations are happening, then it will use FP16 and if any softmax computation is happening then it will use FP32 as we are cmputing exponentiation operation and we dont want any overflow/underflow error ocurring..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eedc3f-1597-4c96-b849-e51a0fe56b20",
   "metadata": {
    "id": "23eedc3f-1597-4c96-b849-e51a0fe56b20"
   },
   "source": [
    "# Training Loop/Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "460dd08a-8404-4667-b825-99645f670e86",
   "metadata": {
    "id": "460dd08a-8404-4667-b825-99645f670e86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7dd8462ab470>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Config\n",
    "import torch\n",
    "from contextlib import nullcontext\n",
    "\n",
    "learning_rate = 1e-4 #more stable training, earlier 1e-4\n",
    "max_iters = 10000 #increase from 25000\n",
    "warmup_steps = 1000 #smoother initial train, earlier 100\n",
    "min_lr = 5e-4 #lower rate, earlier 5e-4\n",
    "eval_iters = 500 # increased from 100\n",
    "batch_size = 32 # changed from 16, better gradient estimate\n",
    "block_size = 128 #changed from 64, capture longer range dependencies\n",
    "\n",
    "gradient_accumulation_steps = 32 # reduced from 50\n",
    "\n",
    "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu' # for later use in torch.autocast\n",
    "# note: float16 data type will automatically use a GradScaler\n",
    "\n",
    "# How to use autocast https://wandb.ai/wandb_fc/tips/reports/How-To-Use-Autocast-in-PyTorch--VmlldzoyMTk4NTky\n",
    "#dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16' # 'float32', 'bfloat16', or 'float16', the latter will auto implement a GradScaler\n",
    "ptdtype = {'float32': torch.float32, 'bfloat16': torch.bfloat16, 'float16': torch.float16}[dtype]\n",
    "\n",
    "ctx = nullcontext() if device_type == 'cpu' else torch.amp.autocast(device_type=device_type, dtype=ptdtype)\n",
    "\n",
    "torch.set_default_device(device)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d642273d-3092-4d80-a13f-69b59d295d03",
   "metadata": {
    "id": "d642273d-3092-4d80-a13f-69b59d295d03"
   },
   "source": [
    "here i am accumulating the gradients after 32 iterations and then will update the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b32e845-4912-4aa2-b571-8d725c22c343",
   "metadata": {
    "id": "6b32e845-4912-4aa2-b571-8d725c22c343"
   },
   "source": [
    "I am going to use the ADAM optimizer with weight decay, annd the learning rate initially is linear in nature and then becomes cosine like (warmup and decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76f64d17-5f3a-4c86-bc20-78300e3d26d5",
   "metadata": {
    "id": "76f64d17-5f3a-4c86-bc20-78300e3d26d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_793900/2132813893.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import LinearLR,SequentialLR, CosineAnnealingLR\n",
    "\n",
    "##PUT IN WEIGHT DECAY, CHANGED BETA2 to 0.95\n",
    "optimizer =  torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.95), weight_decay=0.1, eps=1e-9) #weight decay for regularization\n",
    "\n",
    "scheduler_warmup = LinearLR(optimizer, total_iters = warmup_steps) #Implement linear warmup\n",
    "scheduler_decay = CosineAnnealingLR(optimizer,T_max = max_iters - warmup_steps, eta_min = min_lr) #Implement lr decay\n",
    "scheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_decay], milestones=[warmup_steps]) #Switching from warmup to decay\n",
    "\n",
    "# https://stackoverflow.com/questions/72534859/is-gradscaler-necessary-with-mixed-precision-training-with-pytorch\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DL-s-65q0HVE",
   "metadata": {
    "id": "DL-s-65q0HVE"
   },
   "source": [
    "Now we wll start training the model (Pre Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53fdef4f-ebc7-4c85-9363-2fee3c8dd762",
   "metadata": {
    "id": "53fdef4f-ebc7-4c85-9363-2fee3c8dd762"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be20d37e80414997a44d1fd5d584a1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500: train loss 9.6128, val loss 9.6239\n",
      "The current learning rate: 0.00007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:232: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000: train loss 9.0141, val loss 9.0175\n",
      "The current learning rate: 0.00010\n",
      "Epoch 1500: train loss 8.4175, val loss 8.4205\n",
      "The current learning rate: 0.00010\n",
      "Epoch 2000: train loss 7.8923, val loss 7.8862\n",
      "The current learning rate: 0.00011\n",
      "Epoch 2500: train loss 7.3904, val loss 7.3932\n",
      "The current learning rate: 0.00013\n",
      "Epoch 3000: train loss 6.9145, val loss 6.9143\n",
      "The current learning rate: 0.00015\n",
      "Epoch 3500: train loss 6.4924, val loss 6.4982\n",
      "The current learning rate: 0.00017\n",
      "Epoch 4000: train loss 6.1046, val loss 6.1037\n",
      "The current learning rate: 0.00020\n",
      "Epoch 4500: train loss 5.9228, val loss 5.9232\n",
      "The current learning rate: 0.00023\n",
      "Epoch 5000: train loss 5.7765, val loss 5.7769\n",
      "The current learning rate: 0.00027\n",
      "Epoch 5500: train loss 5.7938, val loss 5.8027\n",
      "The current learning rate: 0.00030\n",
      "Epoch 6000: train loss 5.7941, val loss 5.8013\n",
      "The current learning rate: 0.00033\n",
      "Epoch 6500: train loss 6.0800, val loss 6.0854\n",
      "The current learning rate: 0.00037\n",
      "Epoch 7000: train loss 5.8971, val loss 5.9001\n",
      "The current learning rate: 0.00040\n",
      "Epoch 7500: train loss 6.1303, val loss 6.1270\n",
      "The current learning rate: 0.00043\n",
      "Epoch 8000: train loss 5.9928, val loss 5.9976\n",
      "The current learning rate: 0.00045\n",
      "Epoch 8500: train loss 6.3539, val loss 6.3549\n",
      "The current learning rate: 0.00047\n",
      "Epoch 9000: train loss 6.1683, val loss 6.1733\n",
      "The current learning rate: 0.00049\n",
      "Epoch 9500: train loss 6.4034, val loss 6.4115\n",
      "The current learning rate: 0.00050\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "best_val_loss = float('inf')\n",
    "best_model_params_path = \"best_model_params.pt\"\n",
    "train_loss_list, validation_loss_list = [], []\n",
    "\n",
    "# Ensure model is on the correct device\n",
    "model = model.to(device)\n",
    "\n",
    "# In your training loop\n",
    "for epoch in tqdm(range(max_iters)):\n",
    "    if epoch % eval_iters == 0 and epoch != 0:\n",
    "        # Ensure estimate_loss uses the correct device\n",
    "        losses = estimate_loss(model)\n",
    "        train_ppl = math.exp(losses['train'])\n",
    "        val_ppl = math.exp(losses['val'])\n",
    "        print(f\"Epoch {epoch}: train loss {losses['train']:.4f} (ppl {train_ppl:.2f}), val loss {losses['val']:.4f} (ppl {val_ppl:.2f})\")\n",
    "        print(f\"The current learning rate: {optimizer.param_groups[0]['lr']:.5f}\")\n",
    "        train_loss_list.append(float(losses['train']))\n",
    "        validation_loss_list.append(float(losses['val']))\n",
    "\n",
    "        if losses['val'] < best_val_loss:\n",
    "            best_val_loss = losses['val']\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "    # Ensure X and y are on the correct device\n",
    "    X, y = get_batch(\"train\")\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    with ctx:\n",
    "        logits, loss = model(X, y)\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "    if ((epoch + 1) % gradient_accumulation_steps == 0) or (epoch + 1 == max_iters):\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hoz8CnGgMYVC",
   "metadata": {
    "id": "hoz8CnGgMYVC"
   },
   "source": [
    "# I trained it on T4 GPU, took ~ 2hours training only for 10000 epochs, if i train it longer, its output will be better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c_3j0PuV0R-L",
   "metadata": {
    "id": "c_3j0PuV0R-L"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss_list, \"g\", label=\"train_loss\")\n",
    "plt.plot(validation_loss_list, \"r\", label=\"validation_loss\")\n",
    "plt.xlabel(\"Steps - Every eval window\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79hxRXHIMQVx",
   "metadata": {
    "id": "79hxRXHIMQVx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_793900/1220266581.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device))) # load best model states\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the model\n",
    "model = GPT(config)  # re-create the model with same config\n",
    "device =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "best_model_params_path = \"best_model_params.pt\"\n",
    "model.load_state_dict(torch.load(best_model_params_path, map_location=torch.device(device))) # load best model states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30253411",
   "metadata": {},
   "source": [
    "## Arabic input with round-trip translation\n",
    "\n",
    "Enter Arabic text, translate it to English before feeding the TinyStories model, then translate the model's English output back to Arabic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d9ecc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (4.46.3)\n",
      "Requirement already satisfied: sentencepiece in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: requests in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: filelock in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.13.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages (from requests->transformers) (3.4)\n"
     ]
    }
   ],
   "source": [
    "# Install translation dependencies if they are missing\n",
    "!pip install -U transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e5d5617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d7b89918a743cca29a62351d702838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30732121de0473d9cccf382180f8398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/917k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658000fab8e34e0b9a551b5b352fca11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f7c985f14e4b94b570fbea2f89ed66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b40d0d4f63e4cdcbba988777b5763f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wasfy/anaconda3/envs/slm/lib/python3.8/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbb760b29b9463e82369eface070a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b0d2f000c84244b27f6da1467f8625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "ar_en_model_name = \"Helsinki-NLP/opus-mt-ar-en\"\n",
    "en_ar_model_name = \"Helsinki-NLP/opus-mt-en-ar\"\n",
    "\n",
    "# Load translation models (downloads on first run)\n",
    "ar_en_tokenizer = MarianTokenizer.from_pretrained(ar_en_model_name)\n",
    "ar_en_model = MarianMTModel.from_pretrained(ar_en_model_name).to(device)\n",
    "\n",
    "en_ar_tokenizer = MarianTokenizer.from_pretrained(en_ar_model_name)\n",
    "en_ar_model = MarianMTModel.from_pretrained(en_ar_model_name).to(device)\n",
    "\n",
    "def _translate(text, tokenizer, model, max_length=256):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_tokens = model.generate(**inputs, max_length=max_length)\n",
    "    return tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "def arabic_to_english(text):\n",
    "    return _translate(text, ar_en_tokenizer, ar_en_model)[0]\n",
    "\n",
    "def english_to_arabic(text):\n",
    "    return _translate(text, en_ar_tokenizer, en_ar_model)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9a6ae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English prompt: A girl went to the woods.\n",
      "\n",
      "Model output (English):\n",
      " A girl went to the woods. cleaning; reached st sky and hear room sun. or farm and impressed days flying follow w before barons eggs happily so asks card heads, sometimesboard forget disappointed shout livedOr shout story Lily older bag stubborn pet could hiding save cel. Oprah mighty.\n",
      " Uz had CIA. The welcome doors anger tw plane gratefulir having danceolded stir joy. sour pushed first bath bring else came climb to pouring full mess box.Jack stumbled Ben became ever quickly finish shotir left carrying coming nowam began instructions beach triink shiny and there children like might Sam only workedBecausegy protect he along gathered were sink alive storm. He window sounds planeticked woods ideaia stayed oldicked mine gentle. Let was fair ch everywhere Jane.\n",
      "\n",
      "\n",
      "\n",
      "The on talked moving little dreamed slide storm kissed sharingemon. make feed respectful landscape forest stuck original remembered pur humble follows sign deeplove lovely slips just started coming nose poured attractive sleeping busy plants above redThat car.Emily save frogsara forget should adventure carrots yet the louder\n",
      "\n",
      "Model output translated to Arabic:\n",
      "    .       .           ... ..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('A girl went to the woods. cleaning; reached st sky and hear room sun. or farm and impressed days flying follow w before barons eggs happily so asks card heads, sometimesboard forget disappointed shout livedOr shout story Lily older bag stubborn pet could hiding save cel. Oprah mighty.\\n Uz had CIA. The welcome doors anger tw plane gratefulir having danceolded stir joy. sour pushed first bath bring else came climb to pouring full mess box.Jack stumbled Ben became ever quickly finish shotir left carrying coming nowam began instructions beach triink shiny and there children like might Sam only workedBecausegy protect he along gathered were sink alive storm. He window sounds planeticked woods ideaia stayed oldicked mine gentle. Let was fair ch everywhere Jane.\\n\\n\\n\\nThe on talked moving little dreamed slide storm kissed sharingemon. make feed respectful landscape forest stuck original remembered pur humble follows sign deeplove lovely slips just started coming nose poured attractive sleeping busy plants above redThat car.Emily save frogsara forget should adventure carrots yet the louder',\n",
       " '   .       .           ... ..............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_story_from_arabic(prompt_arabic, max_new_tokens=200):\n",
    "    english_prompt = arabic_to_english(prompt_arabic)\n",
    "    context = torch.tensor(encoding.encode_ordinary(english_prompt), dtype=torch.long).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(context, max_new_tokens)\n",
    "    english_story = encoding.decode(generated_ids.squeeze().tolist())\n",
    "    arabic_story = english_to_arabic(english_story)\n",
    "    print(f\"English prompt: {english_prompt}\")\n",
    "    print(\"\\nModel output (English):\\n\", english_story)\n",
    "    print(\"\\nModel output translated to Arabic:\\n\", arabic_story)\n",
    "    return english_story, arabic_story\n",
    "\n",
    "sample_prompt_ar = \"    \"\n",
    "generate_story_from_arabic(sample_prompt_ar, max_new_tokens=200)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "slm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
